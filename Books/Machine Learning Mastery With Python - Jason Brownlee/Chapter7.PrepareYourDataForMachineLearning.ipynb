{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "After completing this lesson you will know how to:\n1. Rescale data.\n2. Standardize data. \n3. Normalize data. \n4. Binarize data.\n\n## 7.3 Rescale Data\nWhen your data is comprised of attributes with varying scales, many machine learning algorithms can benefit from rescaling the attributes to all have the same scale. Often this is referred to as normalization and attributes are often rescaled into the range between 0 and 1. This is useful for optimization algorithms in used in the core of machine learning algorithms like gradient descent. It is also useful for algorithms that weight inputs like regression and neural networks and algorithms that use distance measures like K-Nearest Neighbors."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Rescale data (between 0 and 1)\nimport pandas\nimport scipy\nimport numpy\nfrom sklearn.preprocessing import MinMaxScaler\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = scaler.fit_transform(X)\n# summarize transformed data\nnumpy.set_printoptions(precision=3)\nprint(rescaledX[0:5,:])",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[0.353 0.744 0.59  0.354 0.    0.501 0.234 0.483]\n [0.059 0.427 0.541 0.293 0.    0.396 0.117 0.167]\n [0.471 0.92  0.525 0.    0.    0.347 0.254 0.183]\n [0.059 0.447 0.541 0.232 0.111 0.419 0.038 0.   ]\n [0.    0.688 0.328 0.354 0.199 0.642 0.944 0.2  ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 7.4 Standardize Data"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Standardization is a useful technique to transform attributes with a Gaussian distribution and differing means and standard deviations to a standard Gaussian distribution with a mean of 0 and a standard deviation of 1.It is most suitable for techniques that assume a Gaussian distribution in the input variables and work better with rescaled data, such as linear regression, logistic regression and linear discriminate analysis."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Standardize data (0 mean, 1 stdev)\nfrom sklearn.preprocessing import StandardScaler\nimport pandas\nimport numpy\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nscaler = StandardScaler().fit(X)\nrescaledX = scaler.transform(X)\n# summarize transformed data\nnumpy.set_printoptions(precision=3)\nprint(rescaledX[0:5,:])",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[ 0.64   0.848  0.15   0.907 -0.693  0.204  0.468  1.426]\n [-0.845 -1.123 -0.161  0.531 -0.693 -0.684 -0.365 -0.191]\n [ 1.234  1.944 -0.264 -1.288 -0.693 -1.103  0.604 -0.106]\n [-0.845 -0.998 -0.161  0.155  0.123 -0.494 -0.921 -1.042]\n [-1.142  0.504 -1.505  0.907  0.766  1.41   5.485 -0.02 ]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## 7.5 Normalize Data\nNormalizing in scikit-learn refers to rescaling each observation (row) to have a length of 1 (called a unit norm or a vector with the length of 1 in linear algebra). This pre-processing method can be useful for sparse datasets (lots of zeros) with attributes of varying scales when using algorithms that weight input values such as neural networks and algorithms that use distance measures such as K-Nearest Neighbors. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Normalize data (length of 1)\nfrom sklearn.preprocessing import Normalizer\nimport pandas\nimport numpy\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nscaler = Normalizer().fit(X)\nnormalizedX = scaler.transform(X)\n# summarize transformed data\nnumpy.set_printoptions(precision=3)\nprint(normalizedX[0:5,:])",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[0.034 0.828 0.403 0.196 0.    0.188 0.004 0.28 ]\n [0.008 0.716 0.556 0.244 0.    0.224 0.003 0.261]\n [0.04  0.924 0.323 0.    0.    0.118 0.003 0.162]\n [0.007 0.588 0.436 0.152 0.622 0.186 0.001 0.139]\n [0.    0.596 0.174 0.152 0.731 0.188 0.01  0.144]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 7.6 Binarize Data (Make Binary)\nYou can transform your data using a binary threshold. All values above the threshold are marked 1 and all equal to or below are marked as 0. \nIt can be useful when you have probabilities that you want to make crisp values. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# binarization\nfrom sklearn.preprocessing import Binarizer\nimport pandas\nimport numpy\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames=['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']  \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\n# separate array into input and output components\nX = array[:,0:8]\nY = array[:,8]\nbinarizer = Binarizer(threshold=0.0).fit(X)\nbinaryX = binarizer.transform(X)\n# summarize transformed data\nnumpy.set_printoptions(precision=3)\nprint(binaryX[0:5,:])",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1. 1. 1. 1. 0. 1. 1. 1.]\n [1. 1. 1. 1. 0. 1. 1. 1.]\n [1. 1. 1. 0. 0. 1. 1. 1.]\n [1. 1. 1. 1. 1. 1. 1. 1.]\n [0. 1. 1. 1. 1. 1. 1. 1.]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}