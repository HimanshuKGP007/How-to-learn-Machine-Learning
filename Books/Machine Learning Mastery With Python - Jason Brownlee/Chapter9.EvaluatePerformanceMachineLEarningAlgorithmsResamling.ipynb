{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "### 9.1Evaluate Machine Learning Algorithms\n- Train and Test Sets.\n- K-fold Cross Validation.\n- Leave One Out Cross Validation. \n- Repeated Random Test-Train Splits."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 9.2Split into Train and Test Sets"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The simplest method that we can use to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In the training and test dataset can result in meaningful di↵erences in the estimate of accuracy. In the example below we split the Pima Indians dataset into 67%/33% splits for training and test and evaluate the accuracy of a Logistic Regression model."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluate using a train and a test set\nimport pandas\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames=[\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"] \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\ntest_size = 0.33\nseed = 7\nX_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X, Y,\n    test_size=test_size, random_state=seed)\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\nresult = model.score(X_test, Y_test)\nprint(\"Accuracy: %.3f\" % (result*100.0))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 75.591\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note that in addition to specifying the size of the split, we also specify the random seed. \n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 9.3 K-fold Cross Validation\nCross validation is an approach that you can use to estimate the performance of a machine learning algorithm with less variance than a single train-test set split. It works by splitting the dataset into k-parts (e.g. k = 5 or k = 10). \nEach split of the data is called a fold. \n\nThe choice of k must allow the size of each test partition to be large enough to be a reasonable sample of the problem, whilst allowing enough repetitions of the train-test evaluation of the algorithm to provide a fair estimate of the algorithms performance on unseen data. For modest sized datasets in the thousands or tens of thousands of records, k values of 3, 5 and 10 are common. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluate using Cross Validation\nimport pandas\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames=[\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"] \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_folds = 10\nnum_instances = len(X)\nseed = 7\nkfold = cross_validation.KFold(n=num_instances, n_folds=num_folds, random_state=seed) \nmodel = LogisticRegression()\nresults = cross_validation.cross_val_score(model, X, Y, cv=kfold)\nprint(\"Accuracy: %.3f %.3f\" % (results.mean()*100.0, results.std()*100.0))",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 76.951 4.841\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can see that we report both the mean and the standard deviation of the performance measure. When summarizing performance measures, it is a good practice to summarize the distribution of the measures, in this case assuming a Gaussian distribution of performance (a very reasonable assumption) and recording the mean and standard deviation."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 9.4 Leave One Out Cross Validation\nYou can configure cross validation so that the size of the fold is 1 (k is set to the number of observations in your dataset)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The result is a large number of performance measures that can be summarized in an effort to give a more reasonable estimate of the accuracy of your model on unseen data.\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluate using Leave One Out Cross Validation\nimport pandas\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames = [\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"] \ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_folds = 10\nnum_instances = len(X)\nloocv = cross_validation.LeaveOneOut(n=num_instances)\nmodel = LogisticRegression()\nresults = cross_validation.cross_val_score(model, X, Y, cv=loocv) \nprint(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 76.823% (42.196%)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "You can see in the standard deviation that the score has more variance than the k-fold cross validation results described above."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 9.5 Repeated Random Test-Train Splits\n\nAnother variation on k-fold cross validation is to create a random split of the data like the train/test split described above, but repeat the process of splitting and evaluation of the algorithm multiple times, like cross validation. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This has the speed of using a train/test split and the reduction in variance in the estimated performance of k-fold cross validation.　You can also repeat the process many more times as needed to improve the accuracy."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The example below splits the data into a 67%/33% train/test split and repeats the process 10 times."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Evaluate using Shuffle Split Cross Validation\nimport pandas\nfrom sklearn import cross_validation\nfrom sklearn.linear_model import LogisticRegression\nurl = \"http://ftp.ics.uci.edu/pub/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\nnames = [\"preg\", \"plas\", \"pres\", \"skin\", \"test\", \"mass\", \"pedi\", \"age\", \"class\"]\ndataframe = pandas.read_csv(url, names=names)\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_samples = 10\ntest_size = 0.33\nnum_instances = len(X)\nseed = 7\nkfold = cross_validation.ShuffleSplit(n=num_instances, n_iter=num_samples,test_size=test_size, random_state=seed)\nmodel = LogisticRegression()\nresults = cross_validation.cross_val_score(model, X, Y, cv=kfold)\nprint(\"Accuracy: %.3f%% (%.3f%%)\" % (results.mean()*100.0, results.std()*100.0))",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy: 76.496% (1.698%)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### 9.6 What Techniques to Use When\n- Generally k-fold cross validation is the gold standard for evaluating the performance of a machine learning algorithm on unseen data with k set to 3, 5, or 10.\n- Using a train/test split is good for speed when using a slow algorithm and produces performance estimates with lower bias when using large datasets.\n- Techniques like leave-one-out cross validation and repeated random splits can be useful intermediates when trying to balance variance in the estimated performance, model training speed and dataset size."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}