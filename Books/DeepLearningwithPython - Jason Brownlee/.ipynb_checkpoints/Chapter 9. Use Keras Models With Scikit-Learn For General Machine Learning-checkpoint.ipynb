{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In the next sections we will work through examples of using the KerasClassifier wrapper for a classification neural network created in Keras and used in the scikit-learn library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9.2 Evaluate Deep Learning Models with Cross Valida-tion\n",
    "\n",
    "The KerasClassifier and KerasRegressor classes in Keras take an argument build_fn which is the name of the function to call to create your model.\n",
    "\n",
    "In the example below we define a function create model() that create a simple multi-layer neural network for the problem.\n",
    "\n",
    "We pass this function name to the KerasClassifier class by the build fn argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init='uniform', activation='relu')) \n",
    "    model.add(Dense(8, init='uniform', activation='relu')) \n",
    "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "  # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "691/691 [==============================] - 1s 790us/step - loss: 0.6771 - acc: 0.6512\n",
      "77/77 [==============================] - 0s 716us/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 0s 596us/step - loss: 0.6818 - acc: 0.6512\n",
      "77/77 [==============================] - 0s 844us/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 0s 672us/step - loss: 0.6763 - acc: 0.6483\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 1s 814us/step - loss: 0.6830 - acc: 0.6208\n",
      "77/77 [==============================] - 0s 1ms/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 1s 855us/step - loss: 0.6899 - acc: 0.6151\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 1s 851us/step - loss: 0.6797 - acc: 0.6512\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 1s 979us/step - loss: 0.6822 - acc: 0.6252\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "691/691 [==============================] - 1s 1ms/step - loss: 0.6795 - acc: 0.6295\n",
      "77/77 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "692/692 [==============================] - 1s 1ms/step - loss: 0.6791 - acc: 0.6098\n",
      "76/76 [==============================] - 0s 3ms/step\n",
      "Epoch 1/1\n",
      "692/692 [==============================] - 1s 1ms/step - loss: 0.6761 - acc: 0.6503\n",
      "76/76 [==============================] - 0s 3ms/step\n",
      "0.6510594735488611\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, nb_epoch=150, batch_size=10)\n",
    "# evaluate using 10-fold cross validation\n",
    "kfold = StratifiedKFold(y=Y, n_folds=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Grid Search Deep Learning Model Parameters\n",
    "\n",
    "In this example we use a grid search to evaluate different configurations for our neural network model and report on the combination that provides the best estimated performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The create model() function is defined to take two arguments optimizer and init, both of which must have default values. \n",
    "\n",
    "- Optimizers for searching different weight values.\n",
    "- Initializers for preparing the network weights using different schemes.\n",
    "- Number of epochs for training the model for different number of exposures to the training dataset.\n",
    "- Batches for varying the number of samples before weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with grid search via sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import numpy\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='rmsprop', init='glorot_uniform'):\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=8, init=init, activation='relu')) \n",
    "    model.add(Dense(8, init=init, activation='relu')) \n",
    "    model.add(Dense(1, init=init, activation='sigmoid'))\n",
    "  # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "# grid search epochs, batch size and optimizer\n",
    "optimizers = ['rmsprop', 'adam']\n",
    "init = ['glorot_uniform', 'normal', 'uniform']\n",
    "epochs = numpy.array([50, 100, 150])\n",
    "batches = numpy.array([5, 10, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = dict(optimizer=optimizers, nb_epoch=epochs, batch_size=batches, init=init) \n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"glorot_uniform\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 4.1291 - acc: 0.6504\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 1.0260 - acc: 0.5566\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 1.9527 - acc: 0.5352\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 8.5485 - acc: 0.3691\n",
      "256/256 [==============================] - 0s 1ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 3.0896 - acc: 0.5313\n",
      "256/256 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 5.7901 - acc: 0.6387\n",
      "256/256 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 5.3517 - acc: 0.6680\n",
      "256/256 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 2ms/step - loss: 4.5514 - acc: 0.5801\n",
      "256/256 [==============================] - 0s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 1s 3ms/step - loss: 3.5848 - acc: 0.6172\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 1.9839 - acc: 0.6445\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 5.6980 - acc: 0.6465\n",
      "256/256 [==============================] - 1s 2ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 4.4044 - acc: 0.4824\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 3ms/step - loss: 10.6490 - acc: 0.3320\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 9.3767 - acc: 0.3535\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 10.1589 - acc: 0.3613\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 1.5666 - acc: 0.6621\n",
      "256/256 [==============================] - 1s 3ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 4ms/step - loss: 2.0831 - acc: 0.4707\n",
      "256/256 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 2s 5ms/step - loss: 3.0710 - acc: 0.5215\n",
      "256/256 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"normal\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"normal\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6629 - acc: 0.6563\n",
      "256/256 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6869 - acc: 0.5703\n",
      "256/256 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6790 - acc: 0.6543\n",
      "256/256 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 5ms/step - loss: 0.6837 - acc: 0.6328\n",
      "256/256 [==============================] - 1s 4ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6783 - acc: 0.6465\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6764 - acc: 0.6016\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6811 - acc: 0.5938\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6714 - acc: 0.6406\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 6ms/step - loss: 0.6762 - acc: 0.6250\n",
      "256/256 [==============================] - 1s 5ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 3s 7ms/step - loss: 0.6711 - acc: 0.6191\n",
      "256/256 [==============================] - 2s 6ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 7ms/step - loss: 0.6676 - acc: 0.6348\n",
      "256/256 [==============================] - 1s 6ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 0.6769 - acc: 0.6348\n",
      "256/256 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 0.6791 - acc: 0.6680\n",
      "256/256 [==============================] - 2s 6ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 0.6894 - acc: 0.5938\n",
      "256/256 [==============================] - 2s 6ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 0.6716 - acc: 0.6387\n",
      "256/256 [==============================] - 2s 6ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 9ms/step - loss: 0.6776 - acc: 0.6660\n",
      "256/256 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 9ms/step - loss: 0.6752 - acc: 0.6445\n",
      "256/256 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 9ms/step - loss: 0.6794 - acc: 0.6387\n",
      "256/256 [==============================] - 2s 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(12, input_dim=8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(8, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "512/512 [==============================] - 4s 8ms/step - loss: 0.6829 - acc: 0.6348\n",
      "256/256 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 9ms/step - loss: 0.6889 - acc: 0.6133\n",
      "256/256 [==============================] - 2s 7ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 9ms/step - loss: 0.6820 - acc: 0.6348\n",
      "256/256 [==============================] - 2s 8ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 10ms/step - loss: 0.6751 - acc: 0.6641\n",
      "256/256 [==============================] - 2s 8ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 10ms/step - loss: 0.6824 - acc: 0.6445\n",
      "256/256 [==============================] - 2s 8ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 10ms/step - loss: 0.6801 - acc: 0.6270\n",
      "256/256 [==============================] - 2s 8ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 10ms/step - loss: 0.6733 - acc: 0.6621\n",
      "256/256 [==============================] - 2s 9ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 5s 10ms/step - loss: 0.6889 - acc: 0.6465\n",
      "256/256 [==============================] - 2s 8ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 11ms/step - loss: 0.6797 - acc: 0.6426\n",
      "256/256 [==============================] - 2s 9ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 11ms/step - loss: 0.6818 - acc: 0.6445\n",
      "256/256 [==============================] - 2s 9ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6816 - acc: 0.6211\n",
      "256/256 [==============================] - 2s 10ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6805 - acc: 0.6270\n",
      "256/256 [==============================] - 2s 9ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6749 - acc: 0.6543\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6844 - acc: 0.6465\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6798 - acc: 0.6426\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6861 - acc: 0.6406\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 0.6788 - acc: 0.6543\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 0.6765 - acc: 0.6367\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 2.3589 - acc: 0.6016\n",
      "256/256 [==============================] - 3s 10ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 5.6980 - acc: 0.6465\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 5.8043 - acc: 0.6387\n",
      "256/256 [==============================] - 3s 11ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.9893 - acc: 0.5664\n",
      "256/256 [==============================] - 3s 12ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 2.6288 - acc: 0.5039\n",
      "256/256 [==============================] - 3s 12ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 6.3561 - acc: 0.4180\n",
      "256/256 [==============================] - 3s 12ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 3.3730 - acc: 0.5156\n",
      "256/256 [==============================] - 3s 12ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 6.6128 - acc: 0.4316\n",
      "256/256 [==============================] - 3s 12ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 5.7948 - acc: 0.6387\n",
      "256/256 [==============================] - 3s 13ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 8s 15ms/step - loss: 3.7698 - acc: 0.5137\n",
      "256/256 [==============================] - 3s 13ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 8s 16ms/step - loss: 3.8973 - acc: 0.5918\n",
      "256/256 [==============================] - 3s 14ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 8s 16ms/step - loss: 4.0466 - acc: 0.5137\n",
      "256/256 [==============================] - 3s 13ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 8s 16ms/step - loss: 4.9587 - acc: 0.3926\n",
      "256/256 [==============================] - 3s 14ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 8s 16ms/step - loss: 5.2922 - acc: 0.4688\n",
      "256/256 [==============================] - 4s 14ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 8s 16ms/step - loss: 3.9150 - acc: 0.5703\n",
      "256/256 [==============================] - 4s 14ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 17ms/step - loss: 1.6050 - acc: 0.5293\n",
      "256/256 [==============================] - 4s 14ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 17ms/step - loss: 5.6980 - acc: 0.6465\n",
      "256/256 [==============================] - 4s 14ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 18ms/step - loss: 10.1820 - acc: 0.3613\n",
      "256/256 [==============================] - 4s 15ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 18ms/step - loss: 0.6728 - acc: 0.6543\n",
      "256/256 [==============================] - 4s 15ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 19ms/step - loss: 0.6848 - acc: 0.6387\n",
      "256/256 [==============================] - 4s 16ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 18ms/step - loss: 0.6806 - acc: 0.6230\n",
      "256/256 [==============================] - 4s 16ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 18ms/step - loss: 0.6739 - acc: 0.6680\n",
      "256/256 [==============================] - 4s 17ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 9s 18ms/step - loss: 0.6755 - acc: 0.6445\n",
      "256/256 [==============================] - 4s 16ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 10s 20ms/step - loss: 0.6813 - acc: 0.6289\n",
      "256/256 [==============================] - 4s 17ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 10s 19ms/step - loss: 0.6757 - acc: 0.6289\n",
      "256/256 [==============================] - 4s 16ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 10s 19ms/step - loss: 0.6866 - acc: 0.5918\n",
      "256/256 [==============================] - 5s 18ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 10s 20ms/step - loss: 0.6892 - acc: 0.5762\n",
      "256/256 [==============================] - 4s 17ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 10s 20ms/step - loss: 0.6708 - acc: 0.6543\n",
      "256/256 [==============================] - 4s 17ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 21ms/step - loss: 0.6872 - acc: 0.6289\n",
      "256/256 [==============================] - 4s 17ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 21ms/step - loss: 0.6795 - acc: 0.6387\n",
      "256/256 [==============================] - 5s 19ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 21ms/step - loss: 0.6731 - acc: 0.6387\n",
      "256/256 [==============================] - 5s 18ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 21ms/step - loss: 0.6826 - acc: 0.6348\n",
      "256/256 [==============================] - 5s 19ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 22ms/step - loss: 0.6842 - acc: 0.6270\n",
      "256/256 [==============================] - 5s 18ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 22ms/step - loss: 0.6869 - acc: 0.6055\n",
      "256/256 [==============================] - 5s 19ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 11s 22ms/step - loss: 0.6846 - acc: 0.6133\n",
      "256/256 [==============================] - 5s 19ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 12s 23ms/step - loss: 0.6859 - acc: 0.6387\n",
      "256/256 [==============================] - 5s 20ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 12s 23ms/step - loss: 0.6674 - acc: 0.6680\n",
      "256/256 [==============================] - 5s 20ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 12s 23ms/step - loss: 0.6846 - acc: 0.6348\n",
      "256/256 [==============================] - 5s 20ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 12s 24ms/step - loss: 0.6816 - acc: 0.6387\n",
      "256/256 [==============================] - 5s 20ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 13s 24ms/step - loss: 0.6769 - acc: 0.6523\n",
      "256/256 [==============================] - 5s 20ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 12s 24ms/step - loss: 0.6896 - acc: 0.5684\n",
      "256/256 [==============================] - 5s 21ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 13s 25ms/step - loss: 0.6850 - acc: 0.6387\n",
      "256/256 [==============================] - 5s 21ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 12s 24ms/step - loss: 0.6818 - acc: 0.6484\n",
      "256/256 [==============================] - 5s 21ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 13s 25ms/step - loss: 0.6851 - acc: 0.6426\n",
      "256/256 [==============================] - 5s 21ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 13s 26ms/step - loss: 0.6848 - acc: 0.6387\n",
      "256/256 [==============================] - 5s 21ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 13s 25ms/step - loss: 0.6727 - acc: 0.6680\n",
      "256/256 [==============================] - 6s 22ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 37ms/step - loss: 0.6854 - acc: 0.6445\n",
      "256/256 [==============================] - 5s 21ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 26ms/step - loss: 0.6823 - acc: 0.6387\n",
      "256/256 [==============================] - 6s 23ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 26ms/step - loss: 0.6659 - acc: 0.6680\n",
      "256/256 [==============================] - 6s 23ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 27ms/step - loss: 0.6809 - acc: 0.6348\n",
      "256/256 [==============================] - 6s 23ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 13s 26ms/step - loss: 0.6764 - acc: 0.6309\n",
      "256/256 [==============================] - 6s 23ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 27ms/step - loss: 0.6694 - acc: 0.6504\n",
      "256/256 [==============================] - 6s 23ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 28ms/step - loss: 0.6788 - acc: 0.6465\n",
      "256/256 [==============================] - 6s 24ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 27ms/step - loss: 0.6849 - acc: 0.6387\n",
      "256/256 [==============================] - 6s 24ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 14s 28ms/step - loss: 3.9941 - acc: 0.6367\n",
      "256/256 [==============================] - 6s 24ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 15s 29ms/step - loss: 5.6980 - acc: 0.6465\n",
      "256/256 [==============================] - 6s 24ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 15s 29ms/step - loss: 2.5985 - acc: 0.5586\n",
      "256/256 [==============================] - 6s 25ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 15s 30ms/step - loss: 10.6156 - acc: 0.3320\n",
      "256/256 [==============================] - 7s 26ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 15s 30ms/step - loss: 3.2536 - acc: 0.5664\n",
      "256/256 [==============================] - 7s 25ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 30ms/step - loss: 5.8239 - acc: 0.6387\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 15s 30ms/step - loss: 5.2675 - acc: 0.6680\n",
      "256/256 [==============================] - 7s 26ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 15s 30ms/step - loss: 3.3024 - acc: 0.5977\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 31ms/step - loss: 1.6899 - acc: 0.4395\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 31ms/step - loss: 10.6367 - acc: 0.3320\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 32ms/step - loss: 5.5126 - acc: 0.6523\n",
      "256/256 [==============================] - 7s 26ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 31ms/step - loss: 5.8097 - acc: 0.6387\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 31ms/step - loss: 10.6490 - acc: 0.3320\n",
      "256/256 [==============================] - 7s 28ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 31ms/step - loss: 9.6361 - acc: 0.3320\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 32ms/step - loss: 2.0096 - acc: 0.5371\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 32ms/step - loss: 9.4277 - acc: 0.3301\n",
      "256/256 [==============================] - 7s 28ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 16s 32ms/step - loss: 4.6276 - acc: 0.6289\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 17s 32ms/step - loss: 5.1182 - acc: 0.6074\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 17s 33ms/step - loss: 0.6911 - acc: 0.6289\n",
      "256/256 [==============================] - 7s 27ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 17s 33ms/step - loss: 0.6871 - acc: 0.6055\n",
      "256/256 [==============================] - 7s 28ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 17s 33ms/step - loss: 0.6905 - acc: 0.5801\n",
      "256/256 [==============================] - 7s 29ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 17s 32ms/step - loss: 0.6900 - acc: 0.5488\n",
      "256/256 [==============================] - 8s 30ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 18s 34ms/step - loss: 0.6854 - acc: 0.6094\n",
      "256/256 [==============================] - 8s 30ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 17s 34ms/step - loss: 0.6958 - acc: 0.5918\n",
      "256/256 [==============================] - 8s 29ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 18s 35ms/step - loss: 0.6710 - acc: 0.6465\n",
      "256/256 [==============================] - 8s 31ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 18s 36ms/step - loss: 0.6827 - acc: 0.6328\n",
      "256/256 [==============================] - 8s 30ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 36ms/step - loss: 0.6777 - acc: 0.6387\n",
      "256/256 [==============================] - 8s 31ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 18s 36ms/step - loss: 0.6882 - acc: 0.5430\n",
      "256/256 [==============================] - 8s 31ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 18s 36ms/step - loss: 0.6938 - acc: 0.5371\n",
      "256/256 [==============================] - 8s 31ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 37ms/step - loss: 0.7000 - acc: 0.5098\n",
      "256/256 [==============================] - 8s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 36ms/step - loss: 0.6633 - acc: 0.6680\n",
      "256/256 [==============================] - 8s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 37ms/step - loss: 0.6835 - acc: 0.6230\n",
      "256/256 [==============================] - 8s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 37ms/step - loss: 0.6720 - acc: 0.6387\n",
      "256/256 [==============================] - 8s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 38ms/step - loss: 0.6753 - acc: 0.6680\n",
      "256/256 [==============================] - 8s 32ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 40ms/step - loss: 0.6966 - acc: 0.4844\n",
      "256/256 [==============================] - 9s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 38ms/step - loss: 0.6713 - acc: 0.6387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 8s 32ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 38ms/step - loss: 0.6735 - acc: 0.6641\n",
      "256/256 [==============================] - 8s 32ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 38ms/step - loss: 0.6850 - acc: 0.5957\n",
      "256/256 [==============================] - 9s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 19s 38ms/step - loss: 0.6826 - acc: 0.6309\n",
      "256/256 [==============================] - 9s 33ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 38ms/step - loss: 0.6841 - acc: 0.6719\n",
      "256/256 [==============================] - 9s 34ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 39ms/step - loss: 0.6897 - acc: 0.5977\n",
      "256/256 [==============================] - 9s 34ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 39ms/step - loss: 0.6866 - acc: 0.6445\n",
      "256/256 [==============================] - 9s 36ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 39ms/step - loss: 0.6852 - acc: 0.6250\n",
      "256/256 [==============================] - 9s 34ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 20s 40ms/step - loss: 0.6797 - acc: 0.6445\n",
      "256/256 [==============================] - 9s 37ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 21s 40ms/step - loss: 0.6781 - acc: 0.6406\n",
      "256/256 [==============================] - 9s 34ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 21s 41ms/step - loss: 0.6875 - acc: 0.6660\n",
      "256/256 [==============================] - 9s 37ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 21s 41ms/step - loss: 0.6898 - acc: 0.6035\n",
      "256/256 [==============================] - 9s 35ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 21s 42ms/step - loss: 0.6839 - acc: 0.6387\n",
      "256/256 [==============================] - 9s 36ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 21s 42ms/step - loss: 0.6861 - acc: 0.6504\n",
      "256/256 [==============================] - 9s 36ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 22s 43ms/step - loss: 0.6842 - acc: 0.6172\n",
      "256/256 [==============================] - 9s 37ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 22s 42ms/step - loss: 0.6858 - acc: 0.6152\n",
      "256/256 [==============================] - 10s 38ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 22s 42ms/step - loss: 0.6901 - acc: 0.6250\n",
      "256/256 [==============================] - 10s 38ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 22s 43ms/step - loss: 0.6905 - acc: 0.6152\n",
      "256/256 [==============================] - 10s 39ms/step\n",
      "Epoch 1/1\n",
      "512/512 [==============================] - 22s 43ms/step - loss: 0.6815 - acc: 0.6328\n",
      "256/256 [==============================] - 10s 39ms/step\n",
      "Epoch 1/1\n",
      "768/768 [==============================] - 22s 29ms/step - loss: 0.6718 - acc: 0.6510\n",
      "Best: 0.653646 using {'batch_size': 20, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.614583 (0.054718) with: {'batch_size': 5, 'init': 'glorot_uniform', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.631510 (0.031304) with: {'batch_size': 5, 'init': 'glorot_uniform', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.585938 (0.046983) with: {'batch_size': 5, 'init': 'glorot_uniform', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.634115 (0.026557) with: {'batch_size': 5, 'init': 'glorot_uniform', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.351563 (0.024080) with: {'batch_size': 5, 'init': 'glorot_uniform', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.549479 (0.047877) with: {'batch_size': 5, 'init': 'glorot_uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.652344 (0.026107) with: {'batch_size': 5, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.649740 (0.023510) with: {'batch_size': 5, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'uniform', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'uniform', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'uniform', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'uniform', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 5, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.645833 (0.031948) with: {'batch_size': 10, 'init': 'glorot_uniform', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.505208 (0.025780) with: {'batch_size': 10, 'init': 'glorot_uniform', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.579427 (0.075228) with: {'batch_size': 10, 'init': 'glorot_uniform', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.574219 (0.053274) with: {'batch_size': 10, 'init': 'glorot_uniform', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.531250 (0.036782) with: {'batch_size': 10, 'init': 'glorot_uniform', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.479167 (0.138377) with: {'batch_size': 10, 'init': 'glorot_uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.652344 (0.026107) with: {'batch_size': 10, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.652344 (0.026107) with: {'batch_size': 10, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'uniform', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'uniform', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'uniform', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'uniform', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 10, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.606771 (0.062201) with: {'batch_size': 20, 'init': 'glorot_uniform', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.540365 (0.120624) with: {'batch_size': 20, 'init': 'glorot_uniform', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.561198 (0.076436) with: {'batch_size': 20, 'init': 'glorot_uniform', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.571615 (0.133741) with: {'batch_size': 20, 'init': 'glorot_uniform', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.440104 (0.095168) with: {'batch_size': 20, 'init': 'glorot_uniform', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.566406 (0.105734) with: {'batch_size': 20, 'init': 'glorot_uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.630208 (0.022628) with: {'batch_size': 20, 'init': 'normal', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.653646 (0.024360) with: {'batch_size': 20, 'init': 'normal', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.649740 (0.024360) with: {'batch_size': 20, 'init': 'normal', 'nb_epoch': 150, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'uniform', 'nb_epoch': 50, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'uniform', 'nb_epoch': 50, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'uniform', 'nb_epoch': 100, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'uniform', 'nb_epoch': 100, 'optimizer': 'adam'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'rmsprop'}\n",
      "0.651042 (0.024774) with: {'batch_size': 20, 'init': 'uniform', 'nb_epoch': 150, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "for params, mean_score, scores in grid_result.grid_scores_:\n",
    "    print(\"%f (%f) with: %r\" % (scores.mean(), scores.std(), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
